from mcp.server.fastmcp import FastMCP
import time
import openai
from youtube_transcript_api._api import YouTubeTranscriptApi
from supabase import create_client, Client
import xml.etree.ElementTree as ET
from datetime import datetime
import requests
import re
from dotenv import load_dotenv
import os
import numpy as np
load_dotenv()

YOUTUBE_API_KEY = os.getenv("YOUTUBE_API_KEY")
YOUTUBE_API_URL = 'https://www.googleapis.com/youtube/v3'
SUPABASE_URL = os.getenv("SUPABASE_URL")
SUPABASE_KEY = os.getenv("SUPABASE_KEY")
supabase: Client = create_client(SUPABASE_URL, SUPABASE_KEY)


# Create an MCP server
mcp = FastMCP("youtube_agent_server")



### Tool 1 : ìœ íŠœë¸Œ ì˜ìƒ URLì— ëŒ€í•œ ìë§‰ì„ ê°€ì ¸ì˜µë‹ˆë‹¤.

@mcp.tool()
def get_youtube_transcript(url: str) -> str:
    """ ìœ íŠœë¸Œ ì˜ìƒ URLì— ëŒ€í•œ ìë§‰ì„ ê°€ì ¸ì˜µë‹ˆë‹¤."""
    
    # 1. ìœ íŠœë¸Œ URLì—ì„œ ë¹„ë””ì˜¤ IDë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤.
    video_id_match = re.search(r"(?:v=|\/)([0-9A-Za-z_-]{11}).*", url)
    if not video_id_match:
        raise ValueError("ìœ íš¨í•˜ì§€ ì•Šì€ YouTube URLì´ ì œê³µë˜ì—ˆìŠµë‹ˆë‹¤")
    video_id = video_id_match.group(1)
    
    print(f"ìë§‰ ì¶”ì¶œ ì‹œë„: ë¹„ë””ì˜¤ ID '{video_id}'")
    
    # 2. youtube_transcript_apië¥¼ ì‚¬ìš©í•˜ì—¬ ìë§‰ì„ ê°€ì ¸ì˜µë‹ˆë‹¤.
    try:
        # ê°„ë‹¨í•œ ë°©ì‹ìœ¼ë¡œ ìë§‰ ê°€ì ¸ì˜¤ê¸°
        languages = ["ko", "en"]
        transcript_list = YouTubeTranscriptApi.get_transcript(video_id, languages=languages)
        
        # 3. ìë§‰ ëª©ë¡ì˜ 'text' ë¶€ë¶„ì„ í•˜ë‚˜ì˜ ë¬¸ìì—´ë¡œ ê²°í•©í•©ë‹ˆë‹¤.
        transcript_text = " ".join([entry['text'] for entry in transcript_list])
        
        if not transcript_text.strip():
            raise Exception("ìë§‰ ë‚´ìš©ì´ ë¹„ì–´ìˆìŠµë‹ˆë‹¤")
        
        print(f"ìë§‰ ì¶”ì¶œ ì„±ê³µ: {video_id} (ê¸¸ì´: {len(transcript_text)}ì)")
        return transcript_text

    except Exception as e:
        error_msg = f"ë¹„ë””ì˜¤ ID '{video_id}'ì— ëŒ€í•œ ìë§‰ì„ ì°¾ì„ ìˆ˜ ì—†ê±°ë‚˜ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ì˜¤ë¥˜: {str(e)}"
        print(f"ìë§‰ ì¶”ì¶œ ì‹¤íŒ¨: {error_msg}")
        raise RuntimeError(error_msg)


### Tool 2 : ìœ íŠœë¸Œì—ì„œ íŠ¹ì • í‚¤ì›Œë“œë¡œ ë™ì˜ìƒì„ ê²€ìƒ‰í•˜ê³  ì„¸ë¶€ ì •ë³´ë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤
@mcp.tool()
def search_youtube_videos(query: str) :
    """ìœ íŠœë¸Œì—ì„œ íŠ¹ì • í‚¤ì›Œë“œë¡œ ë™ì˜ìƒì„ ê²€ìƒ‰í•˜ê³  ì„¸ë¶€ ì •ë³´ë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤"""
    try:
        # 1. ë™ì˜ìƒ ê²€ìƒ‰
        max_results: int = 20
        search_url = f"{YOUTUBE_API_URL}/search?part=snippet&q={requests.utils.quote(query)}&type=video&maxResults={max_results}&key={YOUTUBE_API_KEY}"

        search_response = requests.get(search_url)
        search_data = search_response.json()
        video_ids = [item['id']['videoId'] for item in search_data.get('items', [])]

        if not video_ids:
            return []

        video_details_url = f"{YOUTUBE_API_URL}/videos?part=snippet,statistics&id={','.join(video_ids)}&key={YOUTUBE_API_KEY}"
        details_response = requests.get(video_details_url)
        details_response.raise_for_status()
        details_data = details_response.json()

        videos = []
        for item in details_data.get('items', []):
            snippet = item.get('snippet', {})
            statistics = item.get('statistics', {})
            thumbnails = snippet.get('thumbnails', {})
            
            # ì¸ë„¤ì¼ URL ìš°ì„ ìˆœìœ„: high > medium > default
            thumbnail_url = ""
            if thumbnails.get('high'):
                thumbnail_url = thumbnails['high']['url']
            elif thumbnails.get('medium'):
                thumbnail_url = thumbnails['medium']['url']
            elif thumbnails.get('default'):
                thumbnail_url = thumbnails['default']['url']
            else:
                # ì¸ë„¤ì¼ì´ ì—†ìœ¼ë©´ YouTube ê¸°ë³¸ ì¸ë„¤ì¼ ì‚¬ìš©
                video_id = item.get('id', '')
                thumbnail_url = f"https://img.youtube.com/vi/{video_id}/mqdefault.jpg"
            
            view_count = statistics.get('viewCount')
            like_count = statistics.get('likeCount')

            video_card = {
                "title": snippet.get('title', 'N/A'),
                "publishedDate": snippet.get('publishedAt', ''),
                "channelName": snippet.get('channelTitle', 'N/A'),
                "channelId": snippet.get('channelId', ''),
                "thumbnailUrl": thumbnail_url,
                "viewCount": int(view_count) if view_count is not None else None,
                "likeCount": int(like_count) if like_count is not None else None,
                "url": f"https://www.youtube.com/watch?v={item.get('id', '')}",
            }
            videos.append(video_card)

        if not videos:
            return []

        return videos

    except Exception as e:
        print(f"YouTube ê²€ìƒ‰ ì˜¤ë¥˜: {e}")
        return []
    

### Tool 3 : YouTube ë™ì˜ìƒ URLë¡œë¶€í„° ì±„ë„ ì •ë³´ì™€ ìµœê·¼ 5ê°œì˜ ë™ì˜ìƒì„ ê°€ì ¸ì˜µë‹ˆë‹¤
@mcp.tool()
def get_channel_info(video_url: str) -> dict:
    """YouTube ë™ì˜ìƒ URLë¡œë¶€í„° ì±„ë„ ì •ë³´ì™€ ìµœê·¼ 5ê°œì˜ ë™ì˜ìƒì„ ê°€ì ¸ì˜µë‹ˆë‹¤"""
    def extract_video_id(url):
        match = re.search(r"(?:v=|\/)([0-9A-Za-z_-]{11})", url)
        return match.group(1) if match else None

    def fetch_recent_videos(channel_id):
        rss_url = f"https://www.youtube.com/feeds/videos.xml?channel_id={channel_id}"
        try:
            response = requests.get(rss_url)
            if response.status_code != 200:
                return []

            root = ET.fromstring(response.text)
            ns = {'atom': 'http://www.w3.org/2005/Atom'}
            videos = []

            for entry in root.findall('.//atom:entry', ns)[:5]:  
                title = entry.find('./atom:title', ns).text
                link = entry.find('./atom:link', ns).attrib['href']
                published = entry.find('./atom:published', ns).text
                video_id = link.split('v=')[1] if 'v=' in link else None
                
                # ì¸ë„¤ì¼ URL ìƒì„± (ì—¬ëŸ¬ í¬ê¸° ì‹œë„)
                thumbnail_url = ""
                if video_id:
                    # ë¨¼ì € mqdefault.jpg ì‹œë„
                    thumbnail_url = f"https://img.youtube.com/vi/{video_id}/mqdefault.jpg"
                    # ë§Œì•½ ì‹¤íŒ¨í•˜ë©´ hqdefault.jpg ì‹œë„
                    # ì‹¤ì œë¡œëŠ” í”„ë¡ íŠ¸ì—”ë“œì—ì„œ onerrorë¡œ ì²˜ë¦¬
                
                videos.append({
                    'title': title,
                    'url': link,
                    'publishedDate': published,
                    'thumbnail': thumbnail_url,
                    'videoId': video_id,  # video_id ì¶”ê°€
                    'updatedDate': datetime.now().strftime("%Y-%m-%d %H:%M:%S")
                })

            return videos
        except Exception as e:
            print(f"RSS í”¼ë“œ ê°€ì ¸ì˜¤ê¸° ì‹¤íŒ¨: {e}")
            return []

    video_id = extract_video_id(video_url)
    if not video_id:
        raise ValueError("Invalid YouTube URL")

    video_api = f"{YOUTUBE_API_URL}/videos?part=snippet,statistics&id={video_id}&key={YOUTUBE_API_KEY}"
    video_data = requests.get(video_api).json()
    if not video_data.get('items'):
        raise ValueError("No video found")

    video_info = video_data['items'][0]
    channel_id = video_info['snippet']['channelId']

    channel_api = f"{YOUTUBE_API_URL}/channels?part=snippet,statistics&id={channel_id}&key={YOUTUBE_API_KEY}"
    channel_data = requests.get(channel_api).json()['items'][0]

    return {
        'channelTitle': channel_data['snippet']['title'],
        'channelUrl': f"https://www.youtube.com/channel/{channel_id}",
        'channelThumbnail': channel_data['snippet']['thumbnails']['default']['url'],
        'subscriberCount': channel_data['statistics'].get('subscriberCount', '0'),
        'viewCount': channel_data['statistics'].get('viewCount', '0'),
        'videoCount': channel_data['statistics'].get('videoCount', '0'),
        'videos': fetch_recent_videos(channel_id)
    }


# ì´ë¯¸ ìƒë‹¨ì— import, í™˜ê²½ì„¤ì •, supabase client ìƒì„±ì´ ìˆìœ¼ë¯€ë¡œ ì•„ë˜ ì¤‘ë³µ ì œê±°

# ìë§‰ ì²­í‚¹ í•¨ìˆ˜ ì¶”ê°€

def chunk_transcript(transcript: str, chunk_size: int = 300) -> list:
    """ìë§‰ í…ìŠ¤íŠ¸ë¥¼ chunk_size(ê¸°ë³¸ 300)ìì”© ë‚˜ëˆ  ë¦¬ìŠ¤íŠ¸ë¡œ ë°˜í™˜"""
    return [transcript[i:i+chunk_size] for i in range(0, len(transcript), chunk_size)]

@mcp.tool()
def save_channel_youtube_embeddings(channel_id: str) -> str:
    """YouTube ì±„ë„ ID ê¸°ë°˜ìœ¼ë¡œ ìµœëŒ€ 3ê°œì˜ ìƒˆë¡œìš´ ì˜ìƒ ìë§‰ì„ 300ìì”© ì²­í‚¹í•˜ì—¬ ì„ë² ë”©í•˜ê³  supabaseì— ì €ì¥ (ì´ë¯¸ ì €ì¥ëœ ì˜ìƒì€ ê±´ë„ˆëœ€)"""
    openai.api_key = os.getenv("OPENAI_API_KEY")
    max_results = 3
    new_video_ids = []
    next_page_token = ""
    tried_video_ids = set()

    # ì¶©ë¶„í•œ ìˆ˜ì˜ ìƒˆë¡œìš´ ì˜ìƒì„ ì°¾ì„ ë•Œê¹Œì§€ ë°˜ë³µ (ìµœëŒ€ 10í˜ì´ì§€ê¹Œì§€)
    page_count = 0
    max_pages = 10  # ìµœëŒ€ 10í˜ì´ì§€ê¹Œì§€ ì¡°íšŒ
    
    while len(new_video_ids) < max_results and page_count < max_pages:
        page_count += 1
        print(f"ğŸ“„ {page_count}í˜ì´ì§€ ì¡°íšŒ ì¤‘... (í˜„ì¬ {len(new_video_ids)}ê°œ ì°¾ìŒ)")
        
        search_url = (
            f"{YOUTUBE_API_URL}/search?part=snippet&channelId={channel_id}"
            f"&maxResults=50&order=date&type=video&key={YOUTUBE_API_KEY}"
        )
        if next_page_token:
            search_url += f"&pageToken={next_page_token}"
        resp = requests.get(search_url)
        data = resp.json()
        page_video_ids = [item["id"]["videoId"] for item in data.get("items", [])]
        if not page_video_ids:
            break

        # ì´ë¯¸ ì €ì¥ëœ ì˜ìƒ ì¡°íšŒ
        try:
            # ê° ì˜ìƒ IDë³„ë¡œ ê°œë³„ ì¡°íšŒ
            existing_ids = set()
            for vid in page_video_ids:
                try:
                    resp_db = supabase.table("youtube_videos").select("video_id").eq("video_id", vid).limit(1).execute()
                    if resp_db.data:
                        existing_ids.add(vid)
                        print(f"ğŸ” ì´ë¯¸ ì €ì¥ë¨: {vid}")
                except Exception as e:
                    print(f"âŒ ì˜ìƒ {vid} ì¡°íšŒ ì˜¤ë¥˜: {str(e)}")
            
            print(f"ğŸ” í˜„ì¬ í˜ì´ì§€ ì˜ìƒ: {len(page_video_ids)}ê°œ")
            print(f"ğŸ” ì´ë¯¸ ì €ì¥ëœ ì˜ìƒ: {len(existing_ids)}ê°œ")
            print(f"ğŸ” ìƒˆë¡œìš´ ì˜ìƒ í›„ë³´: {len(page_video_ids) - len(existing_ids)}ê°œ")
        except Exception as e:
            print(f"âŒ DB ì¡°íšŒ ì˜¤ë¥˜: {str(e)}")
            existing_ids = set()

        # ìƒˆë¡œìš´ ì˜ìƒë§Œ ì¶”ê°€
        new_found_this_page = 0
        for vid in page_video_ids:
            if vid not in existing_ids and vid not in new_video_ids and vid not in tried_video_ids:
                new_video_ids.append(vid)
                new_found_this_page += 1
                print(f"âœ… ìƒˆë¡œìš´ ì˜ìƒ ì¶”ê°€: {vid}")
                if len(new_video_ids) >= max_results:
                    break
            tried_video_ids.add(vid)
        
        print(f"ğŸ“ˆ ì´ë²ˆ í˜ì´ì§€ì—ì„œ ì°¾ì€ ìƒˆë¡œìš´ ì˜ìƒ: {new_found_this_page}ê°œ")

        next_page_token = data.get("nextPageToken")
        if not next_page_token:
            break
    
    print(f"ğŸ“Š ì°¾ì€ ìƒˆë¡œìš´ ì˜ìƒ: {len(new_video_ids)}ê°œ (ëª©í‘œ: {max_results}ê°œ)")
    
    # ì¶©ë¶„í•œ ì˜ìƒì„ ì°¾ì§€ ëª»í–ˆë‹¤ë©´ ê²½ê³ 
    if len(new_video_ids) < max_results:
        print(f"âš ï¸ ìƒˆë¡œìš´ ì˜ìƒì´ ë¶€ì¡±í•©ë‹ˆë‹¤. (ì°¾ìŒ: {len(new_video_ids)}ê°œ, ëª©í‘œ: {max_results}ê°œ)")
        print(f"ğŸ’¡ ì±„ë„ì— ìƒˆë¡œìš´ ì˜ìƒì´ ì—†ê±°ë‚˜ ì´ë¯¸ ëª¨ë‘ ì €ì¥ë˜ì—ˆì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.")

    if not new_video_ids:
        return "ì €ì¥í•  ìƒˆë¡œìš´ ì˜ìƒì´ ì—†ìŠµë‹ˆë‹¤."

    count = 0
    # ìƒì„¸ ì •ë³´ ì¡°íšŒ ë° ì„ë² ë”©/ì €ì¥
    for i in range(0, len(new_video_ids), 50):
        batch_ids = new_video_ids[i:i + 50]
        details_url = f"{YOUTUBE_API_URL}/videos?part=snippet&id={','.join(batch_ids)}&key={YOUTUBE_API_KEY}"
        details_resp = requests.get(details_url)
        details_resp.raise_for_status()
        video_data = details_resp.json()

        for video in video_data.get("items", []):
            video_id = video["id"]
            url = f"https://www.youtube.com/watch?v={video_id}"
            print(f"ì²˜ë¦¬ ì¤‘: {video_id} - ìë§‰ ì¶”ì¶œ ì‹œì‘")
            
            # ìë§‰ ê°€ì ¸ì˜¤ê¸°
            try:
                transcript = get_youtube_transcript(url)
                print(f"âœ… {video_id} - ìë§‰ ì¶”ì¶œ ì™„ë£Œ ({len(transcript)}ì)")
            except Exception as e:
                print(f"âŒ {video_id} - ìë§‰ ì¶”ì¶œ ì‹¤íŒ¨: {str(e)}")
                continue
                
            # 300ìì”© ì²­í‚¹
            chunks = chunk_transcript(transcript, chunk_size=300)
            print(f"ğŸ“ {video_id} - {len(chunks)}ê°œ ì²­í¬ë¡œ ë¶„í• ")
            
            chunk_count = 0
            for chunk_idx, chunk in enumerate(chunks):
                # OpenAI ì„ë² ë”©
                try:
                    time.sleep(1)
                    embedding = openai.embeddings.create(
                        input=chunk,
                        model="text-embedding-3-small"
                    ).data[0].embedding
                except Exception as e:
                    print(f"âŒ {video_id} - ì„ë² ë”© ì‹¤íŒ¨ (ì²­í¬ {chunk_idx}): {str(e)}")
                    continue
                    
                # Supabase ì €ì¥
                try:
                    supabase.table("youtube_videos").insert({
                        "video_id": video_id,
                        "url": url,
                        "chunk_index": chunk_idx,
                        "chunk_text": chunk,
                        "embedding": embedding
                    }).execute()
                    count += 1
                    chunk_count += 1
                except Exception as e:
                    print(f"âŒ {video_id} - DB ì €ì¥ ì‹¤íŒ¨ (ì²­í¬ {chunk_idx}): {str(e)}")
                    continue
            
            print(f"ğŸ‰ {video_id} - {chunk_count}ê°œ ì²­í¬ ì €ì¥ ì™„ë£Œ!")

    return f"ì´ {count}ê°œ ìë§‰ ì²­í¬ê°€ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤."


@mcp.tool()
def search_similar_youtube_video(query: str) -> dict:
    """ê²€ìƒ‰ì–´ë¥¼ ì„ë² ë”©í•˜ê³  Supabase RPCë¥¼ í†µí•´ ê°€ì¥ ìœ ì‚¬í•œ ìë§‰ ì²­í¬(ë° ë¹„ë””ì˜¤) ì •ë³´ë¥¼ ë°˜í™˜"""
    try:
        # 1. OpenAIë¥¼ ì‚¬ìš©í•´ ì¿¼ë¦¬ ì„ë² ë”© ìƒì„±
        embedding_response = openai.embeddings.create(
            input=query,
            model="text-embedding-3-small"
        )
        embedding = embedding_response.data[0].embedding

        # 2. Supabase RPC í˜¸ì¶œ (input_vectorëŠ” JSON í˜•íƒœ ë¦¬ìŠ¤íŠ¸ ê·¸ëŒ€ë¡œ ë„˜ê¹€)
        response = supabase.rpc("match_youtube_video", {
            "input_vector": embedding
        }).execute()

        # 3. ê²°ê³¼ ë°˜í™˜
        if response.data and len(response.data) > 0:
            result = response.data[0]
            return {
                "video_id": result.get("video_id"),
                "url": result.get("url"),
                "chunk_index": result.get("chunk_index"),
                "chunk_text": result.get("chunk_text"),
                "score": result.get("score", None)
            }
        else:
            return {"error": "No similar video found."}

    except Exception as e:
        import traceback
        traceback.print_exc()
        return {"error": str(e)}


if __name__ == "__main__":
    mcp.run()